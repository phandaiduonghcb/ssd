{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 00:37:08.746361: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-14 00:37:09.757400: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow   as tf\n",
    "from losses import calc_loss\n",
    "from anchor import multibox_target\n",
    "from metrics import cls_eval, bbox_eval\n",
    "from architecture import SSD\n",
    "from utils import LogWriter\n",
    "from datasets.face_dataset.face_dataset import CLASS_DICT, NUM_TRAIN_EXAMPLES\n",
    "import datasets.face_dataset\n",
    "import tensorflow_datasets as tfds\n",
    "from batch import BatchDatasetForOD\n",
    "from mean_average_precision import MetricBuilder\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 00:37:28.678087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 00:37:28.704875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 00:37:28.705610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 00:37:28.707031: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-14 00:37:28.707691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 00:37:28.708432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 00:37:28.709082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 00:37:30.078673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 00:37:30.079782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 00:37:30.080299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 00:37:30.080701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3360 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 0 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 00:38:10.468175: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "982 6182 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "1097 6067 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "893 6271 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "735 6429 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "754 6410 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "823 6341 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "832 6332 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "870 6294 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "820 6344 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "757 6407 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "745 6419 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "931 6233 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "858 6306 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "767 6397 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "764 6400 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "772 6392 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "763 6401 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "730 6434 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "710 6454 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "885 6279 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "793 6371 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "train total_loss tf.Tensor(82.54803873902236, shape=(), dtype=float64)\n",
      "val total_loss tf.Tensor(21.14482275403863, shape=(), dtype=float64)\n",
      "val box_mae tf.Tensor(0.02808627, shape=(), dtype=float32)\n",
      "val acc_err tf.Tensor(0.87916744, shape=(), dtype=float32)\n",
      "--- Epoch 1 ---\n",
      "748 6416 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "809 6355 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "935 6229 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "791 6373 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "796 6368 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "794 6370 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "845 6319 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "810 6354 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "806 6358 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "742 6422 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "816 6348 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "846 6318 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "809 6355 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "819 6345 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "767 6397 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "929 6235 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "821 6343 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "779 6385 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "767 6397 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "836 6328 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "758 6406 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "train total_loss tf.Tensor(62.27271256173117, shape=(), dtype=float64)\n",
      "val total_loss tf.Tensor(19.90488658336911, shape=(), dtype=float64)\n",
      "val box_mae tf.Tensor(0.024502803, shape=(), dtype=float32)\n",
      "val acc_err tf.Tensor(0.6098013, shape=(), dtype=float32)\n",
      "tf.Tensor(19.90488658336911, shape=(), dtype=float64) inf\n",
      "Smallest val loss!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/tiny_ssd_negative_mining_2/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/tiny_ssd_negative_mining_2/best_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Saving model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "@tf.function(reduce_retracing=True)\n",
    "def training_step(net, X, Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        anchors, cls_preds, bbox_preds = net(X)\n",
    "        bbox_labels, bbox_masks, cls_labels = multibox_target(anchors, Y)\n",
    "        c = tf.nn.softmax(cls_preds[0])\n",
    "        t = tf.cast(c[:,1] >  0.5, tf.float32)\n",
    "        k = tf.cast(c[:,1] <=  0.5, tf.float32)\n",
    "        tf.print(tf.reduce_sum(t),tf.reduce_sum(k), sys.stderr)\n",
    "        l = calc_loss(anchors, cls_preds, cls_labels, bbox_preds, bbox_labels,\n",
    "                    bbox_masks, positive_negative_ratio, image_size[0], image_size[1])\n",
    "        l_mean = tf.reduce_mean(l)\n",
    "    grads = tape.gradient(l_mean, net.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, net.trainable_weights))\n",
    "    return l_mean\n",
    "\n",
    "@tf.function(reduce_retracing=True)\n",
    "def test_step(net, X, Y):\n",
    "    anchors, cls_preds, bbox_preds = net(X, training=False)\n",
    "    bbox_labels, bbox_masks, cls_labels = multibox_target(anchors, Y)\n",
    "    l = calc_loss(anchors, cls_preds, cls_labels, bbox_preds, bbox_labels,\n",
    "                    bbox_masks, positive_negative_ratio, image_size[0], image_size[1])\n",
    "    l_mean = tf.reduce_mean(l)\n",
    "    acc_err = 1-(cls_eval(cls_preds, cls_labels)/float(tf.size(cls_labels)))\n",
    "    mae = (bbox_eval(bbox_preds, bbox_labels, bbox_masks))/float(tf.size(bbox_labels))\n",
    "    return l_mean, acc_err , mae \n",
    "\n",
    "num_epoch = 2\n",
    "start_epoch = -1\n",
    "checkpoint_interval = 2\n",
    "checkpoint_dir = './models/tiny_ssd_negative_mining_2'\n",
    "checkpoint_path = None#'/dl/ssd/models/tiny_ssd_negative_mining_2/9_checkpoint.index'\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "batch_size =32\n",
    "positive_negative_ratio=1000\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, decay=5e-4)\n",
    "image_size = (300,300)\n",
    "log_path = \"./log/tiny_ssd_negative_mining_2\"\n",
    "if not os.path.exists(log_path):\n",
    "    os.makedirs(log_path)\n",
    "logger = LogWriter(log_path = log_path)\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "dataset = tfds.load('face_dataset')\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    net = SSD(num_classes=len(CLASS_DICT.keys()))\n",
    "\n",
    "if checkpoint_path is not None:\n",
    "    net = tf.keras.models.load_model(checkpoint_path)\n",
    "    start_epoch = int(checkpoint_path.split('/')[-1].split('_')[0])\n",
    "\n",
    "for epoch in range(start_epoch+1,num_epoch):\n",
    "    print(f'--- Epoch {epoch} ---')\n",
    "    train_dataset = dataset['train'].shuffle(NUM_TRAIN_EXAMPLES)\n",
    "    valid_dataset = dataset['valid']\n",
    "\n",
    "    batched_train_dataset = BatchDatasetForOD(train_dataset, batch_size, image_size)\n",
    "    batched_valid_dataset = BatchDatasetForOD(valid_dataset, batch_size,image_size)\n",
    "\n",
    "    train_total_loss = 0\n",
    "    for X,Y in batched_train_dataset:\n",
    "      loss = training_step(net, X, Y)\n",
    "      train_total_loss += loss\n",
    "    \n",
    "    total_acc_err = 0\n",
    "    total_box_mae = 0\n",
    "    val_total_loss = 0\n",
    "    \n",
    "    for X,Y in batched_valid_dataset:\n",
    "      loss, acc_err, box_mae = test_step(net, X, Y)\n",
    "      val_total_loss += loss\n",
    "      total_acc_err += acc_err\n",
    "      total_box_mae += box_mae\n",
    "\n",
    "    print('train', 'total_loss', train_total_loss)\n",
    "    print('val', 'total_loss', val_total_loss)\n",
    "    print('val', 'box_mae', total_box_mae)\n",
    "    print('val', 'acc_err', total_acc_err)\n",
    "\n",
    "    if (epoch+1)%checkpoint_interval == 0:\n",
    "        print(val_total_loss, min_val_loss)\n",
    "        if val_total_loss < min_val_loss:\n",
    "            print(\"Smallest val loss!!!\")\n",
    "            dst = os.path.join(checkpoint_dir, 'best_model')\n",
    "            net.save(dst)\n",
    "            min_val_loss = val_total_loss\n",
    "        print('...Saving model...')\n",
    "        dst = os.path.join(checkpoint_dir, f'{epoch}_model')\n",
    "        net.save_weights(dst)\n",
    "        regex = re.compile(f\"^{epoch - checkpoint_interval}_model\")\n",
    "        for file in glob.glob(os.path.join(checkpoint_dir, '*')):\n",
    "            if regex.match(file.split('/')[-1]):\n",
    "                os.remove(file)\n",
    "\n",
    "    logger.add_a_point('train', 'total_loss', train_total_loss,epoch)\n",
    "    logger.add_a_point('val', 'box_mae', total_box_mae,epoch)\n",
    "    logger.add_a_point('val', 'acc_err', total_acc_err, epoch)\n",
    "    logger.add_a_point('val', 'total_loss', val_total_loss, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f7bf9773c40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    new_net = SSD(num_classes=len(CLASS_DICT.keys()))\n",
    "new_net.load_weights('/dl/ssd/models/tiny_ssd_negative_mining_2/1_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "new_net = tf.keras.models.load_model('/dl/ssd/models/tiny_ssd_negative_mining_2/best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558 6606 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "817 6347 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "735 6429 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "810 6354 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "717 6447 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "731 6433 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "659 6505 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n",
      "672 6492 <ipykernel.iostream.OutStream object at 0x7f7e793884f0>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/dl/ssd/train.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646565706c6561726e696e67227d/dl/ssd/train.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m X,Y \u001b[39min\u001b[39;00m batched_train_dataset:\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646565706c6561726e696e67227d/dl/ssd/train.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     loss \u001b[39m=\u001b[39m training_step(net, X, Y)\n",
      "File \u001b[0;32m/dl/ssd/batch.py:26\u001b[0m, in \u001b[0;36mBatchDatasetForOD.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m resized_image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mresize(current_example[\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimage_size)\n\u001b[1;32m     27\u001b[0m X\u001b[39m.\u001b[39mappend(resized_image)\n\u001b[1;32m     28\u001b[0m Y\u001b[39m.\u001b[39mappend(current_example[\u001b[39m'\u001b[39m\u001b[39mobjects\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/image_ops_impl.py:1766\u001b[0m, in \u001b[0;36mresize_images_v2\u001b[0;34m(images, size, method, preserve_aspect_ratio, antialias, name)\u001b[0m\n\u001b[1;32m   1763\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1764\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mResize method is not implemented: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(method))\n\u001b[0;32m-> 1766\u001b[0m \u001b[39mreturn\u001b[39;00m _resize_images_common(\n\u001b[1;32m   1767\u001b[0m     images,\n\u001b[1;32m   1768\u001b[0m     resize_fn,\n\u001b[1;32m   1769\u001b[0m     size,\n\u001b[1;32m   1770\u001b[0m     preserve_aspect_ratio\u001b[39m=\u001b[39;49mpreserve_aspect_ratio,\n\u001b[1;32m   1771\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1772\u001b[0m     skip_resize_if_same\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/image_ops_impl.py:1443\u001b[0m, in \u001b[0;36m_resize_images_common\u001b[0;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[39mif\u001b[39;00m images\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39mndims \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m   1442\u001b[0m   is_batch \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1443\u001b[0m   images \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39;49mexpand_dims(images, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m   1444\u001b[0m \u001b[39melif\u001b[39;00m images\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39mndims \u001b[39m!=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m   1445\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mimages\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m must have either 3 or 4 dimensions.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:561\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    554\u001b[0m       logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    555\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and will \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    556\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mbe removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    559\u001b[0m           \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date),\n\u001b[1;32m    560\u001b[0m           instructions)\n\u001b[0;32m--> 561\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py:372\u001b[0m, in \u001b[0;36mexpand_dims\u001b[0;34m(input, axis, name, dim)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMust specify an axis argument to tf.expand_dims()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 372\u001b[0m \u001b[39mreturn\u001b[39;00m expand_dims_v2(\u001b[39minput\u001b[39;49m, axis, name)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py:442\u001b[0m, in \u001b[0;36mexpand_dims_v2\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mexpand_dims\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    376\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexpand_dims_v2\u001b[39m(\u001b[39minput\u001b[39m, axis, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    378\u001b[0m   \u001b[39m\"\"\"Returns a tensor with a length 1 axis inserted at index `axis`.\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \n\u001b[1;32m    380\u001b[0m \u001b[39m  Given a tensor `input`, this operation inserts a dimension of length 1 at the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39m    InvalidArgumentError: If `axis` is out of range `[-(D+1), D]`.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_array_ops\u001b[39m.\u001b[39;49mexpand_dims(\u001b[39minput\u001b[39;49m, axis, name)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_array_ops.py:2345\u001b[0m, in \u001b[0;36mexpand_dims\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   2344\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   2346\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mExpandDims\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39minput\u001b[39;49m, axis)\n\u001b[1;32m   2347\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   2348\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for X,Y in batched_train_dataset:\n",
    "    loss = training_step(net, X, Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
